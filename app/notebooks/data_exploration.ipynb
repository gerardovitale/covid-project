{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0bb35f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/usr/local/spark-3.1.2-bin-hadoop3.2')\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eea6625c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry\n",
    "from resources.update_local_data import get_covid_data, rearrenge_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d62d2241",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/07/08 13:28:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"covid_deaths\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38d75f8",
   "metadata": {},
   "source": [
    "Update covid local data and convert the data to parquet and jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dcf35dd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] url read -> https://covid.ourworldindata.org/data/owid-covid-data.csv\n",
      "[INFO] data/covid_deaths.csv saved\n",
      "[INFO] data/covid_vaccinations.csv saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/07/08 13:29:03 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , iso_code, continent, location, date, total_cases, new_cases, new_cases_smoothed, total_deaths, new_deaths, new_deaths_smoothed, total_cases_per_million, new_cases_per_million, new_cases_smoothed_per_million, total_deaths_per_million, new_deaths_per_million, new_deaths_smoothed_per_million, reproduction_rate, icu_patients, icu_patients_per_million, hosp_patients, hosp_patients_per_million, weekly_icu_admissions, weekly_icu_admissions_per_million, weekly_hosp_admissions, weekly_hosp_admissions_per_million, population\n",
      " Schema: _c0, iso_code, continent, location, date, total_cases, new_cases, new_cases_smoothed, total_deaths, new_deaths, new_deaths_smoothed, total_cases_per_million, new_cases_per_million, new_cases_smoothed_per_million, total_deaths_per_million, new_deaths_per_million, new_deaths_smoothed_per_million, reproduction_rate, icu_patients, icu_patients_per_million, hosp_patients, hosp_patients_per_million, weekly_icu_admissions, weekly_icu_admissions_per_million, weekly_hosp_admissions, weekly_hosp_admissions_per_million, population\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///app/data/covid_deaths.csv\n",
      "21/07/08 13:29:06 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , new_tests, total_tests, total_tests_per_thousand, new_tests_per_thousand, new_tests_smoothed, new_tests_smoothed_per_thousand, positive_rate, tests_per_case, tests_units, total_vaccinations, people_vaccinated, people_fully_vaccinated, new_vaccinations, new_vaccinations_smoothed, total_vaccinations_per_hundred, people_vaccinated_per_hundred, people_fully_vaccinated_per_hundred, new_vaccinations_smoothed_per_million, stringency_index, population, population_density, median_age, aged_65_older, aged_70_older, gdp_per_capita, extreme_poverty, cardiovasc_death_rate, diabetes_prevalence, female_smokers, male_smokers, handwashing_facilities, hospital_beds_per_thousand, life_expectancy, human_development_index, excess_mortality\n",
      " Schema: _c0, new_tests, total_tests, total_tests_per_thousand, new_tests_per_thousand, new_tests_smoothed, new_tests_smoothed_per_thousand, positive_rate, tests_per_case, tests_units, total_vaccinations, people_vaccinated, people_fully_vaccinated, new_vaccinations, new_vaccinations_smoothed, total_vaccinations_per_hundred, people_vaccinated_per_hundred, people_fully_vaccinated_per_hundred, new_vaccinations_smoothed_per_million, stringency_index, population, population_density, median_age, aged_65_older, aged_70_older, gdp_per_capita, extreme_poverty, cardiovasc_death_rate, diabetes_prevalence, female_smokers, male_smokers, handwashing_facilities, hospital_beds_per_thousand, life_expectancy, human_development_index, excess_mortality\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///app/data/covid_vaccinations.csv\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] jsonl.gz files created:\n",
      "        data/covid_deaths.jsonl.gz\n",
      "        data/covid_vaccinations.jsonl.gz\n",
      "        data/world_population_density.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/07/08 13:29:09 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "21/07/08 13:29:10 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , iso_code, continent, location, date, total_cases, new_cases, new_cases_smoothed, total_deaths, new_deaths, new_deaths_smoothed, total_cases_per_million, new_cases_per_million, new_cases_smoothed_per_million, total_deaths_per_million, new_deaths_per_million, new_deaths_smoothed_per_million, reproduction_rate, icu_patients, icu_patients_per_million, hosp_patients, hosp_patients_per_million, weekly_icu_admissions, weekly_icu_admissions_per_million, weekly_hosp_admissions, weekly_hosp_admissions_per_million, population\n",
      " Schema: _c0, iso_code, continent, location, date, total_cases, new_cases, new_cases_smoothed, total_deaths, new_deaths, new_deaths_smoothed, total_cases_per_million, new_cases_per_million, new_cases_smoothed_per_million, total_deaths_per_million, new_deaths_per_million, new_deaths_smoothed_per_million, reproduction_rate, icu_patients, icu_patients_per_million, hosp_patients, hosp_patients_per_million, weekly_icu_admissions, weekly_icu_admissions_per_million, weekly_hosp_admissions, weekly_hosp_admissions_per_million, population\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///app/data/covid_deaths.csv\n",
      "21/07/08 13:29:12 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , new_tests, total_tests, total_tests_per_thousand, new_tests_per_thousand, new_tests_smoothed, new_tests_smoothed_per_thousand, positive_rate, tests_per_case, tests_units, total_vaccinations, people_vaccinated, people_fully_vaccinated, new_vaccinations, new_vaccinations_smoothed, total_vaccinations_per_hundred, people_vaccinated_per_hundred, people_fully_vaccinated_per_hundred, new_vaccinations_smoothed_per_million, stringency_index, population, population_density, median_age, aged_65_older, aged_70_older, gdp_per_capita, extreme_poverty, cardiovasc_death_rate, diabetes_prevalence, female_smokers, male_smokers, handwashing_facilities, hospital_beds_per_thousand, life_expectancy, human_development_index, excess_mortality\n",
      " Schema: _c0, new_tests, total_tests, total_tests_per_thousand, new_tests_per_thousand, new_tests_smoothed, new_tests_smoothed_per_thousand, positive_rate, tests_per_case, tests_units, total_vaccinations, people_vaccinated, people_fully_vaccinated, new_vaccinations, new_vaccinations_smoothed, total_vaccinations_per_hundred, people_vaccinated_per_hundred, people_fully_vaccinated_per_hundred, new_vaccinations_smoothed_per_million, stringency_index, population, population_density, median_age, aged_65_older, aged_70_older, gdp_per_capita, extreme_poverty, cardiovasc_death_rate, diabetes_prevalence, female_smokers, male_smokers, handwashing_facilities, hospital_beds_per_thousand, life_expectancy, human_development_index, excess_mortality\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///app/data/covid_vaccinations.csv\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] parquet files created: \n",
      "        data/covid_deaths.parquet\n",
      "        data/covid_vaccinations.parquet\n",
      "        data/world_population_density.parquet\n"
     ]
    }
   ],
   "source": [
    "get_covid_data()\n",
    "rearrenge_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960baa6f",
   "metadata": {},
   "source": [
    "# Covid-19 Dataset from Our World in Data\n",
    "- main dataset source: https://ourworldindata.org/covid-deaths\n",
    "- complement dataset #1, population density per country: https://worldpopulationreview.com/country-rankings/countries-by-density\n",
    "- complement dataset #2,GDP evolution per country https://data.worldbank.org/indicator/NY.GDP.PCAP.CD\n",
    "\n",
    "## Overview:\n",
    "The present notebooks tends to explore and analyze covid deaths dataset from Our World in Data. It's going to take special attention to three countries, Soain, Italy and USA, while looking for some global numbers and doing a general analysis.\n",
    "\n",
    "It can be noted that PySpark is going to be used for this analysis, actually it's going to be taken advantage of SQL syntax thank to `spark.sql()` for complex queries.\n",
    "\n",
    "## Steps:\n",
    "1. Load dataset, and check its schema, structure and scope,\n",
    "2. Look at the most infected countries, where are they located (which continent),\n",
    "3. Look at the countries with more deaths, where are they located (which continent),\n",
    "4. Compare the previous results with Spain, Italy and USA,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a8cc7a",
   "metadata": {},
   "source": [
    "### 1. Load dataset, and check its schema, structure and scope\n",
    "- covid_deaths.parquet\n",
    "- world_population_density.parquet\n",
    "- gdp_evol_per_country.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "434fdb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deaths = spark.read.parquet('../data/covid_deaths.parquet', inferSchema=True, header=True)\n",
    "df_pop_density = spark.read.parquet('../data/world_population_density.parquet', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6000d91a",
   "metadata": {},
   "source": [
    "#### 1. covid_deaths.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28b7ae61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- iso_code: string (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- total_cases: double (nullable = true)\n",
      " |-- new_cases: double (nullable = true)\n",
      " |-- new_cases_smoothed: double (nullable = true)\n",
      " |-- total_deaths: double (nullable = true)\n",
      " |-- new_deaths: double (nullable = true)\n",
      " |-- new_deaths_smoothed: double (nullable = true)\n",
      " |-- total_cases_per_million: double (nullable = true)\n",
      " |-- new_cases_per_million: double (nullable = true)\n",
      " |-- new_cases_smoothed_per_million: double (nullable = true)\n",
      " |-- total_deaths_per_million: double (nullable = true)\n",
      " |-- new_deaths_per_million: double (nullable = true)\n",
      " |-- new_deaths_smoothed_per_million: double (nullable = true)\n",
      " |-- reproduction_rate: double (nullable = true)\n",
      " |-- icu_patients: double (nullable = true)\n",
      " |-- icu_patients_per_million: double (nullable = true)\n",
      " |-- hosp_patients: double (nullable = true)\n",
      " |-- hosp_patients_per_million: double (nullable = true)\n",
      " |-- weekly_icu_admissions: double (nullable = true)\n",
      " |-- weekly_icu_admissions_per_million: double (nullable = true)\n",
      " |-- weekly_hosp_admissions: double (nullable = true)\n",
      " |-- weekly_hosp_admissions_per_million: double (nullable = true)\n",
      " |-- population: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_deaths.createOrReplaceTempView(\"covid_deaths\")\n",
    "df_deaths.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a00f0f",
   "metadata": {},
   "source": [
    "Continents that appear in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4228281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|    continent|\n",
      "+-------------+\n",
      "|       Europe|\n",
      "|       Africa|\n",
      "|         null|\n",
      "|North America|\n",
      "|South America|\n",
      "|      Oceania|\n",
      "|         Asia|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT DISTINCT continent\n",
    "    FROM covid_deaths\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4fd8f6",
   "metadata": {},
   "source": [
    "There are 231 countries from 6 different continents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bae8254f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "231"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT DISTINCT location\n",
    "    FROM covid_deaths\n",
    "\"\"\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4339bcb5",
   "metadata": {},
   "source": [
    "This is the range of the dataset. The records start on january 2020 and should end today since it's udtated everytime the function `update_local_data` run at the beginning of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38ffdb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|     Start|       End|\n",
      "+----------+----------+\n",
      "|2020-01-01|2021-07-07|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT min(date(date)) as Start, max(date(date)) as End\n",
    "    FROM covid_deaths\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1778a7d2",
   "metadata": {},
   "source": [
    "#### 2. world_population_density.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f88a098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- rank: integer (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- density: double (nullable = true)\n",
      " |-- densityMi: double (nullable = true)\n",
      " |-- pop2021: double (nullable = true)\n",
      " |-- area: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pop_density.createOrReplaceTempView(\"world_population_density\")\n",
    "df_pop_density.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b97b8d",
   "metadata": {},
   "source": [
    "world_population_density.csv has 232 countries contemplated, one more than covid_deaths.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a78975c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pop_density.select('country').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2f065d",
   "metadata": {},
   "source": [
    "Now, let's compare these two tables or datasets:\n",
    "- `covid_deaths.csv`\n",
    "- `world_population_density.csv`\n",
    "\n",
    "The idea is to enhance covid_deaths dataset by adding the population density per country. So let's compare which countries in `covid_deaths.csv` appear in `world_population_density.csv`.\n",
    "\n",
    "For better result, it can be taken advantage of the iso_code standard, so that the language or any local convention can't affect when two countries name are compared (e.g. Czechia and Czech Republic refer to the same country).\n",
    "\n",
    "In the case of `covid_deaths` table, it already have the iso_code as the second column, but the `world_population_density` just have the country name. Therefore, for this second case, it's going to be used `pycountry` (a pyhotn package available here: https://pypi.org/project/pycountry/) to decode the country name to effectively compare the two datasets.\n",
    "\n",
    "More specifically, it's going to be used map transformation of `PySpark` that recieve a function as parameters to later applied it to each row in a dataframe. \n",
    "\n",
    "The following is a encoding function (`encode_country`) that recieve a row as parameter, take the two most important component (country and population density, the rest of elements are not going to be used), and return the iso_code of that country and the density as a row. Noted that has a try/except block to ensure that if a country can't be read by `pycountry` don't break, and instead return just `None`.\n",
    "\n",
    "After checked what countries were not encode because `pycountry.country.search_fuzzy` didn't recognize them, it was tried to manually do it. To do that, it was created a map or python Dict to asign these countries with their respective iso code, and then update the `encode_country` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d307f77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ISO_MAP = {\n",
    "    'Macau': 'MAC',\n",
    "    'South Korea': 'KOR',\n",
    "    'United States Virgin Islands': 'VIR',\n",
    "    'North Korea': 'PRK',\n",
    "    'Cape Verde': 'CPV',\n",
    "    'Ivory Coast': 'CIV',\n",
    "    'DR Congo': 'COD',\n",
    "    'Laos': 'LAO',\n",
    "    'Sint Maarten': 'SXM',\n",
    "    'Curacao': 'CUW'\n",
    "}\n",
    "\n",
    "\n",
    "# overwrited function \n",
    "def encode_country(row):\n",
    "    country, iso_code, density = (row[1], ISO_MAP[row[1]], row[2]) \\\n",
    "                                    if row[1] in ISO_MAP.keys() \\\n",
    "                                    else (row[1], None, row[2])\n",
    "    try:\n",
    "        iso_code = pycountry.countries.search_fuzzy(country)[0].alpha_3 \\\n",
    "                    if iso_code is None else None\n",
    "    except LookupError: \n",
    "        pass\n",
    "    return (country, iso_code, density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0c2113c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rdd = df_pop_density.rdd.map(encode_country)\n",
    "df_pop_density = rdd.toDF(['country', 'iso_code', 'density'])\n",
    "\n",
    "# Create a new tempView for the new table with encode countries\n",
    "df_pop_density.createOrReplaceTempView(\"population_density_encoded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2703f779",
   "metadata": {},
   "source": [
    "Now, the two tables can be easily compared with each other by looking at their iso_codes. Noted that there are 10 iso_code in `covid_deaths` that are not in `population_density_encode`, and that the `WHERE continent IS NOT NULL` clause is added in the SQL query beacuse when it's not passed, continents as a whole are considered as country in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18b079f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT iso_code \n",
    "    FROM covid_deaths\n",
    "    WHERE continent IS NOT NULL\n",
    "    EXCEPT\n",
    "    SELECT iso_code FROM population_density_encoded\n",
    "\"\"\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5384bf83",
   "metadata": {},
   "source": [
    "Here are the countries and the iso_code from `covid_deaths` that didn't find a iso_code in the `population_density_encoded` table (the new one). There are 10 countries as it was commented before. Therefore, it can be affirmed that for these 10 countries are not population density information available in the dataset consulted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9068fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|            location|iso_code|\n",
      "+--------------------+--------+\n",
      "|               Macao|     MAC|\n",
      "|     Northern Cyprus|OWID_CYN|\n",
      "|             Curacao|     CUW|\n",
      "|Democratic Republ...|     COD|\n",
      "|               Niger|     NER|\n",
      "|         South Korea|     KOR|\n",
      "|       Cote d'Ivoire|     CIV|\n",
      "|            Pitcairn|     PCN|\n",
      "|Sint Maarten (Dut...|     SXM|\n",
      "|              Jersey|     JEY|\n",
      "|          Cape Verde|     CPV|\n",
      "|Bonaire Sint Eust...|     BES|\n",
      "|        Saint Helena|     SHN|\n",
      "|              Kosovo|OWID_KOS|\n",
      "|                Laos|     LAO|\n",
      "|            Guernsey|     GGY|\n",
      "+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT DISTINCT location, iso_code\n",
    "    FROM covid_deaths\n",
    "    WHERE iso_code IN (\n",
    "        SELECT iso_code FROM covid_deaths\n",
    "        EXCEPT\n",
    "        SELECT iso_code FROM population_density_encoded) AND\n",
    "        continent IS NOT NULL \n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c6a0d6",
   "metadata": {},
   "source": [
    "### 2. Look at the most infected countries and where they are located, in which continent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb99cc2",
   "metadata": {},
   "source": [
    "The following are the top 20 countries that have the higher rate of infected people; \n",
    "noted that neither Spain nor Italy, two of the most affected european countries at the beginning of the pandemic, appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "470e4e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 53:=======================================>              (148 + 4) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+-------------+------------+-----------+-------------------------+\n",
      "|iso_code|     location|    continent|  population| TotalCases|PercentPopulationInfected|\n",
      "+--------+-------------+-------------+------------+-----------+-------------------------+\n",
      "|     AND|      Andorra|       Europe|     77265.0|    14021.0|       18.146638193231087|\n",
      "|     SYC|   Seychelles|       Africa|     98340.0|    16304.0|       16.579214968476712|\n",
      "|     MNE|   Montenegro|       Europe|    628062.0|   100392.0|       15.984409182532936|\n",
      "|     BHR|      Bahrain|         Asia|   1701583.0|   266797.0|       15.679340943110034|\n",
      "|     CZE|      Czechia|       Europe| 1.0708982E7|  1668277.0|       15.578296797958945|\n",
      "|     SMR|   San Marino|       Europe|     33938.0|     5092.0|       15.003830514467559|\n",
      "|     MDV|     Maldives|         Asia|    540542.0|    74724.0|       13.823902675462776|\n",
      "|     SVN|     Slovenia|       Europe|   2078932.0|   257550.0|       12.388572594004998|\n",
      "|     LUX|   Luxembourg|       Europe|    625976.0|    71748.0|       11.461781282349483|\n",
      "|     SWE|       Sweden|       Europe|  1.009927E7|  1092083.0|        10.81348453898153|\n",
      "|     URY|      Uruguay|South America|   3473727.0|   374665.0|       10.785677746121097|\n",
      "|     SRB|       Serbia|       Europe|   6804596.0|   717196.0|       10.539876283617719|\n",
      "|     LTU|    Lithuania|       Europe|   2722291.0|   278984.0|       10.248132914519426|\n",
      "|     USA|United States|North America|3.31002647E8|3.3770444E7|       10.202469468469236|\n",
      "|     ARG|    Argentina|South America| 4.5195777E7|  4593763.0|       10.164142105577696|\n",
      "|     NLD|  Netherlands|       Europe| 1.7134873E7|  1724262.0|       10.062881703295963|\n",
      "|     EST|      Estonia|       Europe|   1326539.0|   131299.0|        9.897862030441622|\n",
      "|     ISR|       Israel|         Asia|   8655541.0|   844378.0|         9.75534631515234|\n",
      "|     PAN|       Panama|North America|   4314768.0|   411226.0|        9.530663062301379|\n",
      "|     BEL|      Belgium|       Europe| 1.1589616E7|  1091095.0|         9.41441890740815|\n",
      "+--------+-------------+-------------+------------+-----------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_top_infected = spark.sql(\"\"\"\n",
    "    SELECT iso_code, location, continent, population,\n",
    "        MAX(total_cases) as TotalCases, \n",
    "        (MAX(total_cases)/MAX(population))*100 as PercentPopulationInfected\n",
    "    FROM covid_deaths\n",
    "    GROUP BY iso_code, location, population, continent\n",
    "    ORDER BY PercentPopulationInfected desc\n",
    "    LIMIT 20\n",
    "\"\"\")\n",
    "df_top_infected.createOrReplaceTempView(\"top_infected_countries\")\n",
    "df_top_infected.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5a12bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 58:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------------+---------+\n",
      "|     location|PercentPopulationInfected|  density|\n",
      "+-------------+-------------------------+---------+\n",
      "|      Bahrain|       15.679340943110034|2285.3542|\n",
      "|     Maldives|       13.823902675462776|1812.0567|\n",
      "|   San Marino|       15.003830514467559| 557.6557|\n",
      "|       Israel|         9.75534631515234| 423.1957|\n",
      "|  Netherlands|       10.062881703295963| 410.3488|\n",
      "|      Belgium|         9.41441890740815| 381.0379|\n",
      "|   Luxembourg|       11.461781282349483| 245.4811|\n",
      "|   Seychelles|       16.579214968476712|  218.823|\n",
      "|      Andorra|       18.146638193231087| 165.2885|\n",
      "|      Czechia|       15.578296797958945| 135.9862|\n",
      "|     Slovenia|       12.388572594004998| 102.5366|\n",
      "|       Serbia|       10.539876283617719|   98.432|\n",
      "|       Panama|        9.530663062301379|   58.098|\n",
      "|   Montenegro|       15.984409182532936|  45.4715|\n",
      "|    Lithuania|       10.248132914519426|  41.1924|\n",
      "|United States|       10.202469468469236|    35.52|\n",
      "|      Estonia|        9.897862030441622|  29.3007|\n",
      "|       Sweden|        10.81348453898153|  22.5634|\n",
      "|      Uruguay|       10.785677746121097|  19.2514|\n",
      "|    Argentina|       10.164142105577696|  16.4026|\n",
      "+-------------+-------------------------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT tic.location, tic.PercentPopulationInfected, pde.density\n",
    "    FROM top_infected_countries as tic\n",
    "    INNER JOIN population_density_encoded as pde\n",
    "        ON tic.iso_code = pde.iso_code\n",
    "    ORDER BY 3 DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fe02db",
   "metadata": {},
   "source": [
    "The following table shows how many countries are per continent, in order to detect the most affected ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83715354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+----------+\n",
      "|    continent|count(continent)|Percentage|\n",
      "+-------------+----------------+----------+\n",
      "|       Europe|              12|      60.0|\n",
      "|         Asia|               3|      15.0|\n",
      "|South America|               2|      10.0|\n",
      "|North America|               2|      10.0|\n",
      "|       Africa|               1|       5.0|\n",
      "+-------------+----------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 60:====================================================> (195 + 4) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT continent, COUNT(continent), COUNT(continent)/20*100 as Percentage\n",
    "    FROM top_infected_countries\n",
    "    GROUP BY continent\n",
    "    ORDER BY 2 desc\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a31cfb",
   "metadata": {},
   "source": [
    "### 3. Look at the countries with more deaths and where they are located, in which continent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd596faa",
   "metadata": {},
   "source": [
    "Now, let's have a look on the top 20 countries with the higher death rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f370bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 63:==========================>                            (96 + 4) / 200]\r",
      "\r",
      "[Stage 63:===================================>                  (132 + 4) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+-------------+----------+-----------+------------------+\n",
      "|            location|    continent|   population|TotalCases|TotalDeaths|   PercentOfDeaths|\n",
      "+--------------------+-------------+-------------+----------+-----------+------------------+\n",
      "|             Vanuatu|      Oceania|     307150.0|       4.0|        1.0|              25.0|\n",
      "|               Yemen|         Asia|  2.9825968E7|    6934.0|     1364.0|19.671185462936254|\n",
      "|                Peru|South America|  3.2971846E7| 2071637.0|   193743.0| 9.352169323100524|\n",
      "|              Mexico|North America| 1.28932753E8| 2558369.0|   234192.0| 9.153957071868835|\n",
      "|               Sudan|       Africa|  4.3849269E7|   36805.0|     2760.0|7.4989811166961005|\n",
      "|               Syria|         Asia|  1.7500657E7|   25735.0|     1893.0|7.3557412084709535|\n",
      "|               Egypt|       Africa| 1.02334403E8|  282582.0|    16332.0| 5.779561330870331|\n",
      "|             Somalia|       Africa|  1.5893219E7|   14995.0|      775.0|5.1683894631543845|\n",
      "|               China|         Asia|1.439323774E9|   92021.0|     4636.0| 5.037980460981732|\n",
      "|              Taiwan|         Asia|  2.3816775E7|   15128.0|      715.0| 4.726335272342676|\n",
      "|Bosnia and Herzeg...|       Europe|    3280815.0|  205047.0|     9667.0| 4.714528864114081|\n",
      "|             Ecuador|South America|   1.764306E7|  465029.0|    21728.0| 4.672396775254876|\n",
      "|            Bulgaria|       Europe|    6948445.0|  422298.0|    18129.0| 4.292940056547746|\n",
      "|         Afghanistan|         Asia|  3.8928341E7|  129021.0|     5415.0| 4.196991187481108|\n",
      "|            Tanzania|       Africa|  5.9734213E7|     509.0|       21.0|  4.12573673870334|\n",
      "|             Bolivia|South America|  1.1673029E7|  449687.0|    17067.0| 3.795306513196957|\n",
      "|             Hungary|       Europe|    9660350.0|  808338.0|    29999.0|  3.71119506938929|\n",
      "|             Comoros|       Africa|     869595.0|    3966.0|      146.0| 3.681290973272819|\n",
      "|                Mali|       Africa|  2.0250834E7|   14454.0|      527.0|3.6460495364604952|\n",
      "|     North Macedonia|       Europe|    2083380.0|  155741.0|     5486.0|3.5225149446838024|\n",
      "+--------------------+-------------+-------------+----------+-----------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 63:==================================================>   (188 + 4) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_top_deaths = spark.sql(\"\"\"\n",
    "    SELECT location, continent, population, \n",
    "        MAX(total_cases) as TotalCases,\n",
    "        MAX(total_deaths) as TotalDeaths,\n",
    "        (MAX(total_deaths)/MAX(total_cases))*100 as PercentOfDeaths\n",
    "    FROM covid_deaths\n",
    "    GROUP BY location, population, continent\n",
    "    ORDER BY PercentOfDeaths desc\n",
    "    LIMIT 20\n",
    "\"\"\")\n",
    "df_top_deaths.createOrReplaceTempView(\"top_deaths_countries\")\n",
    "df_top_deaths.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0bc3654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+----------+\n",
      "|    continent|count(continent)|Percentage|\n",
      "+-------------+----------------+----------+\n",
      "|       Africa|               6|      30.0|\n",
      "|         Asia|               5|      25.0|\n",
      "|South America|               3|      15.0|\n",
      "|       Europe|               3|      15.0|\n",
      "|      Oceania|               1|       5.0|\n",
      "|North America|               1|       5.0|\n",
      "+-------------+----------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 66:========================================>             (149 + 6) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT continent, COUNT(continent), COUNT(continent)/20*100 as Percentage\n",
    "    FROM top_deaths_countries\n",
    "    WHERE TotalDeaths/TotalCases*100 >= 3.6423\n",
    "    GROUP BY continent\n",
    "    ORDER BY 2 desc\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3d47df",
   "metadata": {},
   "source": [
    "### 4. Compare the previous results with Spain, Italy and USA,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e520291",
   "metadata": {},
   "source": [
    "Just to verify that Spain and Italy are contemplated in the dataset, let's query them. Additionally, it can be interesting to compare their infection and death rate with the US rates.\n",
    "\n",
    "- It can be noted that US have the higher infected rate (10.12%), but the lower death rate (1.79%).\n",
    "- In contrats, Italy have the lower infected rate (7.03%) and the higher death rate (2.99%).\n",
    "- Finally, Spain is in the middle of the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c8808c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+-----------+-----------+-------------------------+------------------+\n",
      "|     location|  Population| TotalCases|TotalDeaths|PercentPopulationInfected|   PercentOfDeaths|\n",
      "+-------------+------------+-----------+-----------+-------------------------+------------------+\n",
      "|United States|3.31002647E8|3.3770444E7|   606218.0|       10.202469468469236| 1.795114094443058|\n",
      "|        Italy| 6.0461828E7|  4265714.0|   127718.0|       7.0552183767913865|2.9940591422678597|\n",
      "|        Spain| 4.6754783E7|  3897996.0|    80969.0|        8.337106387596751| 2.077195564079594|\n",
      "+-------------+------------+-----------+-----------+-------------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT DISTINCT location, \n",
    "        MAX(population) as Population,\n",
    "        MAX(total_cases) as TotalCases, \n",
    "        MAX(total_deaths) as TotalDeaths,\n",
    "        (MAX(total_cases)/MAX(population))*100 as PercentPopulationInfected,\n",
    "        (MAX(total_deaths)/MAX(total_cases))*100 as PercentOfDeaths\n",
    "    FROM covid_deaths\n",
    "    WHERE location LIKE 'Spain' or \n",
    "        location LIKE 'Italy' or \n",
    "        location LIKE '%tates%'\n",
    "    GROUP BY location\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2034384b",
   "metadata": {},
   "source": [
    "Using spark.sql to query a spain dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cc192d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spain = spark.sql(\"\"\"\n",
    "    SELECT DATE(date),\n",
    "        population, total_cases, new_cases, total_deaths, \n",
    "        (total_deaths/total_cases*100) as death_rate,\n",
    "        (new_cases/population*100) as infected_rate\n",
    "    FROM covid_deaths\n",
    "    WHERE location = 'Spain' AND\n",
    "        total_deaths IS NOT NULL\n",
    "    ORDER by 1\n",
    "\"\"\")\n",
    "df_spain.createOrReplaceTempView(\"covid_deaths_spain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbd70b1",
   "metadata": {},
   "source": [
    "This is how it looks like the spain dataframe, the first 20 days since is was reported the first death.\n",
    "\n",
    "The following are some notes realted:\n",
    "- The first covid death was on march (03-march-2020), there were 165 cases in total and 45 new cases.\n",
    "- It's easy to see how the number of new cases and death rate are increasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea0321c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-----------+---------+------------+------------------+--------------------+\n",
      "|      date| population|total_cases|new_cases|total_deaths|        death_rate|       infected_rate|\n",
      "+----------+-----------+-----------+---------+------------+------------------+--------------------+\n",
      "|2020-03-03|4.6754783E7|      165.0|     45.0|         1.0|0.6060606060606061|9.624683746259715E-5|\n",
      "|2020-03-04|4.6754783E7|      222.0|     57.0|         2.0|0.9009009009009009|1.219126607859563...|\n",
      "|2020-03-05|4.6754783E7|      259.0|     37.0|         3.0|1.1583011583011582|7.913628858035766E-5|\n",
      "|2020-03-06|4.6754783E7|      400.0|    141.0|         5.0|              1.25| 3.01573424049471E-4|\n",
      "|2020-03-07|4.6754783E7|      500.0|    100.0|        10.0|               2.0|2.138818610279936...|\n",
      "|2020-03-08|4.6754783E7|      673.0|    173.0|        17.0| 2.526002971768202| 3.70015619578429E-4|\n",
      "|2020-03-09|4.6754783E7|     1073.0|    400.0|        28.0|  2.60950605778192|8.555274441119745E-4|\n",
      "|2020-03-10|4.6754783E7|     1695.0|    622.0|        35.0|2.0648967551622417|0.001330345175594...|\n",
      "|2020-03-11|4.6754783E7|     2277.0|    582.0|        54.0| 2.371541501976284|0.001244792431182...|\n",
      "|2020-03-12|4.6754783E7|     2277.0|      0.0|        55.0|2.4154589371980677|                 0.0|\n",
      "|2020-03-13|4.6754783E7|     5232.0|   2955.0|       133.0|2.5420489296636086|0.006320208993377212|\n",
      "|2020-03-14|4.6754783E7|     6391.0|   1159.0|       195.0|3.0511657017681113|0.002478890769314...|\n",
      "|2020-03-15|4.6754783E7|     7798.0|   1407.0|       289.0|3.7060784816619647|0.003009317784663871|\n",
      "|2020-03-16|4.6754783E7|     9942.0|   2144.0|       342.0|3.4399517199758605|0.004585627100440184|\n",
      "|2020-03-17|4.6754783E7|    11748.0|   1806.0|       533.0| 4.536942458290773|0.003862706410165565|\n",
      "|2020-03-18|4.6754783E7|    13910.0|   2162.0|       623.0| 4.478792235801582|0.004624125835425223|\n",
      "|2020-03-19|4.6754783E7|    17963.0|   4053.0|       830.0| 4.620609029672104|0.008668631827464583|\n",
      "|2020-03-20|4.6754783E7|    20410.0|   2447.0|      1043.0| 5.110240078392945|0.005233689139355005|\n",
      "|2020-03-21|4.6754783E7|    25374.0|   4964.0|      1375.0| 5.418932765823284|0.010617095581429604|\n",
      "|2020-03-22|4.6754783E7|    28768.0|   3394.0|      1772.0| 6.159621802002225|0.007259150363290104|\n",
      "+----------+-----------+-----------+---------+------------+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spain.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "137e77c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql(\"\"\"\n",
    "#     SELECT MONTH(date) AS month, YEAR(date) AS year,\n",
    "#         MAX(population) as population,\n",
    "#         sum(total_cases) as total_cases, \n",
    "#         sum(new_cases) as new_cases, \n",
    "#         sum(total_deaths) as total_deaths,\n",
    "#         (sum(total_deaths)/sum(total_cases)*100) as death_rate,\n",
    "#         (sum(total_cases)/MAX(population)*100) as infected_rate\n",
    "#     FROM covid_deaths_spain\n",
    "#     GROUP BY month, year\n",
    "#     ORDER by year, month\n",
    "# \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64aa2c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
